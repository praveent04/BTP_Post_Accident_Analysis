{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d5928",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "df = pd.read_excel(\"STC dataset.xlsx\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aab36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=[\"object\"])\n",
    "numerical_columns = df.select_dtypes(include=[\"int64\", \"float64\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da356c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.width\", None) \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df = df.isnull().sum().reset_index()\n",
    "null_df.columns = [\"Column\", \"MissingValues\"]\n",
    "print(null_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7935b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df = null_df[null_df[\"MissingValues\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795bc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea6ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad073584",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df.to_csv(\"null_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df[null_df[\"MissingValues\"] > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebeae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"toi\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d1ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_hash = df[df.isin([\"########\"]).any(axis=1)]\n",
    "rows_with_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29855b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_hash.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64968028",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ecde8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = df.select_dtypes(include=\"object\")\n",
    "\n",
    "# Get unique categories for each column\n",
    "categories = {col: obj_cols[col].dropna().unique().tolist() for col in obj_cols.columns}\n",
    "\n",
    "# Convert to DataFrame (each row = column name, categories as list)\n",
    "categories_df = pd.DataFrame.from_dict(categories, orient=\"index\").transpose()\n",
    "\n",
    "# Save to CSV\n",
    "categories_df.to_csv(\"object_columns_categories.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca58a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"toi\",\"doa\",\"dod\", \"toad\", \"poi\", \"education\", \"poi.1\", \"doi\",\"lat-long_nh\",\"residence\", \"nh\", \"prim_hosp\", \"prim_hosp.1\", \"residence.1\", \"toi.1\", \"doi.1\", \"lat-long_home\", \"residence.1\"]\n",
    "df.drop(cols, axis = 1, inplace = True)\n",
    "categories_df.drop(cols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4310e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549dfb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = categories_df.columns\n",
    "for col in cols:\n",
    "    \n",
    "    df[col] = df[col].where(df[col].isna(), df[col].astype(str).str.strip().str.lower())\n",
    "    categories_df[col] = categories_df[col].where(categories_df[col].isna(), categories_df[col].astype(str).str.strip().str.lower())\n",
    "\n",
    "categories_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140e0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"adm_no.1\", \"lat-long_crash\", \"lat-long_prim_hos\"]\n",
    "df.drop(cols, axis = 1, inplace = True)\n",
    "categories_df.drop(cols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743d1ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dist_hometocrash'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dist_hometocrash'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb994dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_cols = [\"dist_hometocrash\",  \"dist_crashtotc\",  \"dist_crashtonh\" ]\n",
    "time_cols = [\"traveltime_hometocrash\",\"traveltime_crashtohosp\",\"traveltime_crashtonh\"]\n",
    "df.drop(dist_cols, axis =1 , inplace = True)\n",
    "categories_df.drop(dist_cols, axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efdb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categroies_df = categories_df.dropna(how=\"all\").reset_index(drop=True)\n",
    "categroies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d073bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"traveltime_hometocrash\", \"traveltime_crashtohosp\", \"traveltime_crashtonh\"], axis = 1, inplace = True)\n",
    "categories_df.drop([\"traveltime_hometocrash\", \"traveltime_crashtohosp\", \"traveltime_crashtonh\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12694bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df_updates = df.isnull().sum().reset_index()\n",
    "null_df_updates.columns = [\"Column\", \"MissingValues\"]\n",
    "null_df_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda002db",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows = null_df_updates.loc[null_df_updates[\"MissingValues\"] > 100, \"Column\"].tolist()\n",
    "\n",
    "# null_columns = null_columns['Column']\n",
    "null_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69827e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(null_rows, axis = 1, inplace = True)\n",
    "# categories_df.drop(null_rows, axis = 1, inplace = True)\n",
    "null_df_updates = null_df_updates[~null_df_updates[\"Column\"].isin(null_rows)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ae0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df_updates[null_df_updates[\"MissingValues\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da78c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5201c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['adm_no', 'casuality_no', 'casuality_no.1'], axis = 1, inplace = True)\n",
    "numerical_columns.drop(['adm_no', 'casuality_no', 'casuality_no.1'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb03a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"familymem\", \"earningfamilymem\"]\n",
    "\n",
    "for col in cols:\n",
    "    df[col] = df[col].fillna(0)  # replaces real NaN with 0\n",
    "    numerical_columns[col] = numerical_columns[col].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff816233",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns['familymem'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1cd9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fill = numerical_columns.columns[numerical_columns.isnull().sum() > 0].tolist()\n",
    "print(columns_to_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = numerical_columns['cost'].mean()\n",
    "df['cost'] = df['cost'].fillna(mean_val)  # replaces real NaN with 0\n",
    "numerical_columns['cost'] = numerical_columns['cost'].fillna(mean_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e938ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_fill:\n",
    "    mean_val = df[col].mode()[0]\n",
    "    df[col] = df[col].fillna(mean_val)\n",
    "    numerical_columns[col] = numerical_columns[col].fillna(mean_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f0397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_updates = df.select_dtypes(include=[\"object\"])\n",
    "categorical_updates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_updates.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59031d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_updates.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc3d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_updates['exp_mot.1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ddd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('exp_mot.1', axis = 1, inplace = True)\n",
    "categories_df.drop('exp_mot.1', axis = 1, inplace = True)\n",
    "categorical_updates.drop('exp_mot.1', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c144ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('exp_mot', axis = 1, inplace = True)\n",
    "categories_df.drop('exp_mot', axis = 1, inplace = True)\n",
    "categorical_updates.drop('exp_mot', axis = 1, inplace = True)\n",
    "columns_to_fill_unknown = categorical_updates.columns[categorical_updates.isnull().sum() > 150].tolist()\n",
    "columns_to_fill_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d41f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_fill_unknown:\n",
    "    df[col] = df[col].fillna('Not known')  # replaces real NaN with 0\n",
    "    categorical_updates[col] = categorical_updates[col].fillna('Not known')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ac5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['helmet'] = df['helmet'].fillna('Not known')  # replaces real NaN with 0\n",
    "categorical_updates['helmet'] = categorical_updates['helmet'].fillna('Not known')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ebb2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fill_unknown = categorical_updates.columns[categorical_updates.isnull().sum() > 100].to_list()\n",
    "columns_to_fill_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_fill_unknown:\n",
    "    df[col] = df[col].fillna('Not known')  # replaces real NaN with 0\n",
    "    categorical_updates[col] = categorical_updates[col].fillna('Not known')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f5a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_updates.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc42e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fill_mode = categorical_updates.columns[categorical_updates.isnull().sum() > 0].to_list()\n",
    "columns_to_fill_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e973e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_fill_mode:\n",
    "    mode_value = df[col].mode()[0]\n",
    "    df[col] = df[col].fillna(mode_value)  # replaces real NaN with 0\n",
    "    categorical_updates[col] = categorical_updates[col].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['interviewee'] = df['interviewee'].replace({\"swlf\": \"self\", \"neice\": \"niece\", \"nephue\": \"nephew\", \"bystandar\": \"bystander\", \"unlce\": \"uncle\", \"hasband\": \"husband\", \"broter\": \"brother\"})\n",
    "df['interviewee'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# create a dictionary to store encoders for each column\n",
    "encoders = {}\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    # categories_df[col] = le.transform(categories_df[col].astype(str))  # convert to str in case of NaN/mixed\n",
    "    encoders[col] = le  # save encoder if you want to inverse transform later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e76d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b3761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_cols = [col for col in df.columns if col.startswith(\"rate_\")]\n",
    "\n",
    "summary = df[rate_cols].describe().T  # mean, std, min, max, quartiles\n",
    "print(summary)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for col in rate_cols:\n",
    "    df[col].plot(kind=\"hist\", bins=10, title=col)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2cf879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_rates(df, adjust_fill_count=60):\n",
    "    # Step 1: Identify rate columns\n",
    "    rate_cols = [col for col in df.columns if col.startswith(\"rate_\") and col != \"rate_bleed_amb\"]\n",
    "\n",
    "    rate_summary = {}\n",
    "\n",
    "    for col in rate_cols:\n",
    "        # Raw counts\n",
    "        counts = df[col].value_counts().sort_index()\n",
    "\n",
    "        # Mode\n",
    "        mode_val = df[col].mode()[0]\n",
    "\n",
    "        # Step 2: Adjust for artificially filled values\n",
    "        if mode_val is not None and mode_val in counts:\n",
    "            counts[mode_val] = max(0, counts[mode_val] - adjust_fill_count)\n",
    "\n",
    "        # Step 3: Normalized counts after adjustment\n",
    "        counts_norm = counts / counts.sum() * 100 if counts.sum() > 0 else counts\n",
    "\n",
    "        # Descriptive statistics\n",
    "        mean_val = df[col].mean()\n",
    "        median_val = df[col].median()\n",
    "        std_val = df[col].std()\n",
    "\n",
    "        rate_summary[col] = {\n",
    "            \"Mean\": mean_val,\n",
    "            \"Median\": median_val,\n",
    "            \"Mode\": mode_val,\n",
    "            \"StdDev\": std_val,\n",
    "            \"Distribution\": counts_norm.to_dict()\n",
    "        }\n",
    "\n",
    "    # Convert to DataFrame for tabular view\n",
    "    rate_summary_df = pd.DataFrame(rate_summary).T\n",
    "\n",
    "    # Step 4: Visualization â€“ Adjusted stacked bar chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    dist_df = pd.DataFrame({\n",
    "        col: pd.Series(rate_summary[col][\"Distribution\"])\n",
    "        for col in rate_cols\n",
    "    }).fillna(0).T\n",
    "    dist_df.plot(kind=\"bar\", stacked=True, ax=ax)\n",
    "    plt.title(\"Adjusted Distribution of Ratings per Rate Column\")\n",
    "    plt.ylabel(\"Proportion (%)\")\n",
    "    plt.xlabel(\"Rate Columns\")\n",
    "    plt.legend(title=\"Rating\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Step 5: Correlation heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(df[rate_cols].corr(), annot=True, cmap=\"coolwarm\", center=0)\n",
    "    plt.title(\"Correlation Between Rate Columns\")\n",
    "    plt.show()\n",
    "\n",
    "    return rate_summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d0f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = analyze_rates(df, adjust_fill_count=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf236c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def post_accident_analysis(df):\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 2: Descriptive Statistics\n",
    "    # ---------------------------\n",
    "\n",
    "    print(\"\\nðŸ“Š DEMOGRAPHICS\")\n",
    "    print(df[[\"age\", \"gender\", \"income\"]].describe(include=\"all\"))\n",
    "\n",
    "    print(\"\\nðŸ“Š ACCIDENT EXPERIENCE\")\n",
    "    exp_cols = [\"helpcaller\", \"info_crashsite\", \"mot\", \"admitted\", \"status_hosp\", \n",
    "                \"transf_mot\", \"predeposit\"]\n",
    "    for col in exp_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col} value counts:\\n\", df[col].value_counts(normalize=True) * 100)\n",
    "\n",
    "    print(\"\\nðŸ“Š HEALTHCARE RATINGS (mean Â± std)\")\n",
    "    rate_cols = [col for col in df.columns if col.startswith(\"rate_\")]\n",
    "    print(df[rate_cols].agg([\"mean\", \"median\", \"std\"]).T)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 3: Comparative Analysis\n",
    "    # ---------------------------\n",
    "\n",
    "    # Gender vs Admission\n",
    "    if \"gender\" in df.columns and \"admitted\" in df.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.countplot(data=df, x=\"gender\", hue=\"admitted\")\n",
    "        plt.title(\"Admission Status by Gender\")\n",
    "        plt.show()\n",
    "\n",
    "    # Insurance vs Cost\n",
    "    if \"health_insur_before\" in df.columns and \"cost\" in df.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.boxplot(data=df, x=\"health_insur_before\", y=\"cost\")\n",
    "        plt.title(\"Hospital Cost by Insurance Status (Before Accident)\")\n",
    "        plt.show()\n",
    "\n",
    "    # Hospital Choice vs Overall Health Rating\n",
    "    if \"choice_hospital\" in df.columns and \"rate_overallhealth\" in df.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.boxplot(data=df, x=\"choice_hospital\", y=\"rate_overallhealth\")\n",
    "        plt.title(\"Overall Health Rating by Hospital Choice\")\n",
    "        plt.show()\n",
    "\n",
    "    # Compensation vs Work Loss\n",
    "    if \"compensator\" in df.columns and \"workloss\" in df.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.boxplot(data=df, x=\"compensator\", y=\"workloss\")\n",
    "        plt.title(\"Work Loss by Compensation Status\")\n",
    "        plt.show()\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 4: Correlation Analysis\n",
    "    # ---------------------------\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(df[numeric_cols].corr(), annot=False, cmap=\"coolwarm\", center=0)\n",
    "    plt.title(\"Correlation Heatmap (Numeric Variables)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Ratings correlation\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(df[rate_cols].corr(), annot=True, cmap=\"coolwarm\", center=0)\n",
    "    plt.title(\"Correlation Between Healthcare Rating Columns\")\n",
    "    plt.show()\n",
    "\n",
    "    return df[rate_cols].agg([\"mean\", \"median\", \"std\"]).T\n",
    "\n",
    "# ---------------------------\n",
    "# Run the analysis\n",
    "# ---------------------------\n",
    "summary = post_accident_analysis(df)\n",
    "print(\"\\nðŸ“Œ SUMMARY OF RATINGS:\\n\", summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29164ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def pca_post_crash(df, n_components=4):\n",
    "    # Step 1: Select relevant numeric columns for PCA\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    # Step 2: Standardize the data (important for PCA)\n",
    "    X = df[numeric_cols].dropna()\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Step 3: Fit PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_result = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Step 4: Create PCA DataFrame\n",
    "    pca_df = pd.DataFrame(\n",
    "        data=pca_result,\n",
    "        columns=[f'PC{i+1}' for i in range(n_components)]\n",
    "    )\n",
    "    \n",
    "    # Step 5: Explained Variance\n",
    "    explained_var = pca.explained_variance_ratio_ * 100\n",
    "    print(\"Explained variance per component (%):\")\n",
    "    for i, var in enumerate(explained_var, 1):\n",
    "        print(f\"PC{i}: {var:.2f}%\")\n",
    "    print(f\"Total Explained Variance ({n_components} PCs): {explained_var.sum():.2f}%\")\n",
    "    \n",
    "    # Step 6: Scree plot\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(range(1, len(pca.explained_variance_ratio_)+1), \n",
    "             pca.explained_variance_ratio_*100, 'o-', linewidth=2)\n",
    "    plt.title(\"Scree Plot (Explained Variance by Components)\")\n",
    "    plt.xlabel(\"Principal Components\")\n",
    "    plt.ylabel(\"Explained Variance (%)\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Step 7: PCA Scatter Plot\n",
    "    if n_components >= 2:\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.scatterplot(x=\"PC1\", y=\"PC2\", data=pca_df, alpha=0.7)\n",
    "        plt.title(\"PCA of Post-Crash Scenario Data\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Step 8: Feature importance in PCs\n",
    "    loadings = pd.DataFrame(\n",
    "        pca.components_.T,\n",
    "        columns=[f'PC{i+1}' for i in range(n_components)],\n",
    "        index=numeric_cols\n",
    "    )\n",
    "    return pca_df, loadings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e03a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results, loadings = pca_post_crash(df)\n",
    "pca_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e975de",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552bda58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_pca(df, variance_threshold=0.80, exclude_cols=None):\n",
    "    # 1. Keep only numeric columns (exclude IDs, categorical, etc.)\n",
    "    numeric_df = df.select_dtypes(include=[np.number]).copy()\n",
    "    \n",
    "    if exclude_cols:\n",
    "        numeric_df = numeric_df.drop(columns=exclude_cols, errors=\"ignore\")\n",
    "    \n",
    "    # Handle NaN by filling with column means\n",
    "    numeric_df = numeric_df.fillna(numeric_df.mean())\n",
    "\n",
    "    # 2. Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(numeric_df)\n",
    "\n",
    "    # 3. Run PCA without fixing n_components\n",
    "    pca = PCA()\n",
    "    pca.fit(X_scaled)\n",
    "\n",
    "    # 4. Compute cumulative variance\n",
    "    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "    # 5. Choose smallest number of components >= threshold\n",
    "    n_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "\n",
    "    print(f\"âœ… Optimal n_components (â‰¥{int(variance_threshold*100)}% variance): {n_components}\")\n",
    "\n",
    "    # 6. Fit PCA again with optimal components\n",
    "    pca_opt = PCA(n_components=n_components)\n",
    "    X_pca = pca_opt.fit_transform(X_scaled)\n",
    "\n",
    "    # 7. Plot explained variance curve\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(cumulative_variance*100, marker='o')\n",
    "    plt.axhline(y=variance_threshold*100, color='r', linestyle='--')\n",
    "    plt.axvline(x=n_components, color='g', linestyle='--')\n",
    "    plt.xlabel(\"Number of Components\")\n",
    "    plt.ylabel(\"Cumulative Explained Variance (%)\")\n",
    "    plt.title(\"PCA Explained Variance Curve\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 8. Return results\n",
    "    pca_df = pd.DataFrame(X_pca, columns=[f\"PC{i+1}\" for i in range(n_components)])\n",
    "    \n",
    "    return pca_opt, pca_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: exclude non-numeric or ID-like columns\n",
    "exclude_cols = [\"interviewee\"]\n",
    "\n",
    "pca_model, pca_data = run_pca(df, variance_threshold=0.80, exclude_cols=exclude_cols)\n",
    "\n",
    "print(pca_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12acd518",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2788478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac5f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1454f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
